{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.clip_by_value\n",
    "tf.clip_by_value(\n",
    "    t,\n",
    "    clip_value_min,\n",
    "    clip_value_max,\n",
    "    name=None\n",
    ")\n",
    "给定的tensor t中的所有值限定在clip_value_min 和 clip_value_max之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin value: [[-0.27354655 -1.3089035   0.3579834   1.6660101 ]\n",
      " [-0.37126926 -0.46291596 -2.008697   -1.3827105 ]\n",
      " [-0.6242001  -0.2117389  -1.2942055  -1.9149228 ]]\n",
      "after clip_by_value(t, 0, 1.0): [[0.        0.        0.3579834 1.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    tensor_ab = tf.random_normal((3, 4), mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "    after_clip_a = tf.clip_by_value(tensor_ab, 0, 1)\n",
    "    with tf.Session() as sess:\n",
    "        output_ab, output_clip = sess.run([tensor_ab, after_clip_a])\n",
    "        print(\"origin value:\", output_ab)\n",
    "        print(\"after clip_by_value(t, 0, 1.0):\", output_clip)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.clip_by_global_norm\n",
    "tf.clip_by_global_norm(\n",
    "    t_list,\n",
    "    clip_norm,\n",
    "    use_norm=None,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "对t_list中的值进行限定，缩小一定尺度(自己理解)\n",
    "输出的list_clipped计算如下：t_list[i] * clip_norm / max(global_norm, clip_norm)\n",
    "\n",
    "参数：\n",
    "use_norm----如果预先已经计算了 global_norm， 可以通过这个参数指定\n",
    "返回值：\n",
    "list_clipped: 和t_list保持相同类型的 tensor list\n",
    "global_norm: global norm的标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin value a1:\n",
      " [[ 0.2801796   1.261506   -0.08506524  1.9679066 ]\n",
      " [ 1.3015199  -0.02672353 -0.21450634  0.42450377]\n",
      " [-0.92664397 -0.11236522 -1.1519778   0.10334326]]\n",
      "origin value a2:\n",
      " [[ 0.4130754   0.64810586  2.023332   -0.4650102 ]\n",
      " [ 0.18793212 -2.3923392   0.00366899  0.10036173]\n",
      " [-0.830722   -0.6703147  -0.5850104  -0.6789748 ]]\n",
      "after clip_by_global_norm(t, 0, 1.0):\n",
      " [array([[ 0.1400898 ,  0.630753  , -0.04253262,  0.9839533 ],\n",
      "       [ 0.65075994, -0.01336176, -0.10725317,  0.21225189],\n",
      "       [-0.46332198, -0.05618261, -0.5759889 ,  0.05167163]],\n",
      "      dtype=float32), array([[ 0.2065377 ,  0.32405293,  1.011666  , -0.2325051 ],\n",
      "       [ 0.09396606, -1.1961696 ,  0.0018345 ,  0.05018086],\n",
      "       [-0.415361  , -0.33515736, -0.2925052 , -0.3394874 ]],\n",
      "      dtype=float32)]\n",
      "global norm:\n",
      "\t 2.0\n",
      "------------------------------\n",
      "origin value a1:\n",
      " [[ 0.2801796   1.261506   -0.08506524  1.9679066 ]\n",
      " [ 1.3015199  -0.02672353 -0.21450634  0.42450377]\n",
      " [-0.92664397 -0.11236522 -1.1519778   0.10334326]]\n",
      "origin value a2:\n",
      " [[ 0.4130754   0.64810586  2.023332   -0.4650102 ]\n",
      " [ 0.18793212 -2.3923392   0.00366899  0.10036173]\n",
      " [-0.830722   -0.6703147  -0.5850104  -0.6789748 ]]\n",
      "after clip_by_global_norm(t, 0, 1.0):\n",
      " [array([[ 0.05934219,  0.26718763, -0.01801686,  0.41680366],\n",
      "       [ 0.2756626 , -0.00566006, -0.04543256,  0.08991013],\n",
      "       [-0.19626369, -0.02379901, -0.2439895 ,  0.02188816]],\n",
      "      dtype=float32), array([[ 0.08748958,  0.13726917,  0.42854282, -0.0984894 ],\n",
      "       [ 0.03980412, -0.5066987 ,  0.00077709,  0.02125667],\n",
      "       [-0.17594735, -0.14197302, -0.12390552, -0.14380722]],\n",
      "      dtype=float32)]\n",
      "global norm:\n",
      "\t 4.7214236\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    tensor_a1 = tf.random_normal((3, 4), mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "    tensor_a2 = tf.random_normal((3, 4), mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "    tensor_norm = tf.constant(2, dtype=tf.float32)\n",
    "    after_clip_a, global_norm = tf.clip_by_global_norm([tensor_a1, tensor_a2], 1, use_norm=tensor_norm)\n",
    "    after_clip_a_2, global_norm_2 = tf.clip_by_global_norm([tensor_a1, tensor_a2], 1)\n",
    "    with tf.Session() as sess:\n",
    "        output_ab, output_a2, clip_list, global_norm, clip_list_2, global_norm_2 = sess.run([tensor_a1, tensor_a2, after_clip_a, \n",
    "                                                                 global_norm, after_clip_a_2, global_norm_2])\n",
    "        print(\"origin value a1:\\n\", output_ab)\n",
    "        print(\"origin value a2:\\n\", output_a2)\n",
    "        print(\"after clip_by_global_norm(t, 0, 1.0):\\n\", clip_list)\n",
    "        print(\"global norm:\\n\\t\", global_norm)\n",
    "        print(\"------------------------------\")\n",
    "        \n",
    "        print(\"origin value a1:\\n\", output_ab)\n",
    "        print(\"origin value a2:\\n\", output_a2)\n",
    "        print(\"after clip_by_global_norm(t, 0, 1.0):\\n\", clip_list_2)\n",
    "        print(\"global norm:\\n\\t\", global_norm_2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.gradients\n",
    "tf.gradients(\n",
    "    ys,\n",
    "    xs,\n",
    "    grad_ys=None,\n",
    "    name='gradients',\n",
    "    colocate_gradients_with_ops=False,\n",
    "    gate_gradients=False,\n",
    "    aggregation_method=None,\n",
    "    stop_gradients=None\n",
    ")\n",
    "计算ys相对于xs的梯度，\n",
    "参数：\n",
    "    ys和xs: 需要求导的目标， 是一个tersor或者一个tensor的list\n",
    "   grad_ys: ys的导数，（用于链式求导）\n",
    "   stop_gradients： 部分偏导求导，(只计算一次，）不链式传播\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "tf.gradients (c=a + b) [3.0, 1.0]\n",
      "tf.gradients (c=a + b) with grad_ys=3: [9.0, 3.0]\n",
      "tf.gradients (2*a + 3 * c) with respect to [a, c]  : [11.0, 3.0]\n",
      "tf.gradients (2*a + 3 * c) with respect to [a, c]  with stop_gradients=[ a, c]: [2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    a = tf.constant(0.)\n",
    "    b = 2.0 * a - 1.0\n",
    "    c = a + b \n",
    "    g = tf.gradients(c , [a, b] )\n",
    "    g_2 = tf.gradients(c , [a, b], grad_ys = tf.constant(3.0) )\n",
    "    g_3 = tf.gradients(2* a + 3 * c , [a, c] )\n",
    "    g_4 = tf.gradients(2* a + 3 * c , [a, c], stop_gradients=[ a, c] )\n",
    "    with tf.Session() as sess:\n",
    "        cc, gg, gg2, gg3, gg4 = sess.run([c, g, g_2, g_3, g_4])\n",
    "        print(cc)\n",
    "        print(\"tf.gradients (c=a + b)\", gg)\n",
    "        print(\"tf.gradients (c=a + b) with grad_ys=3:\", gg2)\n",
    "        print(\"tf.gradients (2*a + 3 * c) with respect to [a, c]  :\", gg3)\n",
    "        print(\"tf.gradients (2*a + 3 * c) with respect to [a, c]  with stop_gradients=[ a, c]:\", gg4)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.trainable_variables\n",
    "tf.trainable_variables(scope=None)\n",
    "参数:\n",
    "    scope: 指定作用域内\n",
    "返回值：\n",
    "    返回所有trainable=True的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
